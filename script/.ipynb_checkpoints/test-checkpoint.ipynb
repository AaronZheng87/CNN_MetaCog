{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe821d2f-7bfb-44ec-b53c-1bd5c3d2211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:03,  3.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import commonsetting\n",
    "from models import perceptual_network, Encoder, Class_out, Conf_out\n",
    "from dataloader import CustomImageDataset, concatenate_transform_steps\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pretrained_model_name   = commonsetting.pretrained_model_name\n",
    "    hidden_layer_size       = commonsetting.hidden_layer_size\n",
    "    hidden_activation_name  = commonsetting.hidden_activation_name\n",
    "    hidden_activation       = commonsetting.hidden_activation\n",
    "    hidden_dropout          = commonsetting.hidden_dropout\n",
    "    resize                  = commonsetting.image_resize\n",
    "    in_shape                = (1,3,resize,resize)\n",
    "\n",
    "    SimpleCNN_args = dict(\n",
    "        pretrained_model_name   = pretrained_model_name,\n",
    "        hidden_layer_size       = hidden_layer_size,\n",
    "        hidden_activation       = hidden_activation,\n",
    "        hidden_dropout          = hidden_dropout,\n",
    "        hidden_layer_type       = commonsetting.hidden_layer_type,\n",
    "        output_layer_size       = commonsetting.output_layer_size,\n",
    "        in_shape                = (1,3,resize,resize),\n",
    "        retrain_encoder         = commonsetting.retrain_encoder,\n",
    "        device                  = commonsetting.device,\n",
    "        )\n",
    "        \n",
    "\n",
    "    tranformer_steps = concatenate_transform_steps(image_resize=commonsetting.image_resize, rotate=0)\n",
    "\n",
    "    dataset_test = CustomImageDataset(commonsetting.test_dir,label_map=commonsetting.label_map , transform=tranformer_steps)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=commonsetting.batch_size, shuffle=True, num_workers=commonsetting.num_workers)\n",
    "    SimpleCNN = perceptual_network(**SimpleCNN_args)\n",
    "    SimpleCNN.load_state_dict(torch.load(\"../models/train_mixed_weight/simplecnn_retest.h5\"))\n",
    "    for p in SimpleCNN.parameters(): p.requires_grad = False\n",
    "    # define loss function\n",
    "    classification_loss = nn.BCELoss()\n",
    "    # when there is no noise\n",
    "    SimpleCNN.eval()\n",
    "    SimpleCNN.to(commonsetting.device)\n",
    "    with torch.no_grad():\n",
    "        # extract features of each image\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_correct_pred = []\n",
    "        confidence_out = []\n",
    "        for idx_batch, (batch_image, batch_label) in tqdm(enumerate(dataloader_test)):\n",
    "            batch_label = torch.vstack(batch_label).T.float()\n",
    "            #记得每一次处理数据之前要做这一步\n",
    "            batch_image = batch_image.to(commonsetting.device)\n",
    "            batch_label = batch_label.to(commonsetting.device)\n",
    "            \n",
    "            features,hidden_representation,prediction, confidence =  SimpleCNN(batch_image.to(commonsetting.device))\n",
    "            correct_preds = batch_label.clone().detach().argmax(1)==prediction.clone().detach().argmax(1)\n",
    "            correct_preds = correct_preds.float()\n",
    "\n",
    "            correct_preds = torch.vstack([1-correct_preds, correct_preds]).T.float()\n",
    "            \n",
    "            \n",
    "            y_correct_pred.append(correct_preds.detach().cpu().numpy())\n",
    "            y_true.append(batch_label.detach().cpu().numpy())\n",
    "            y_pred.append(prediction.detach().cpu().numpy())\n",
    "            confidence_out.append(confidence.detach().cpu().numpy())\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_correct_pred = np.concatenate(y_correct_pred, axis=0)\n",
    "    confidence_out = np.concatenate(confidence_out, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c9f356-4629-4a02-93c4-01168fe98bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ef5757-3322-42bc-be37-d12c46acd702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.650775462962963"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69652cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5799082453494218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_correct_pred, confidence_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e639657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd104c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 201, 1: 66, 2: 93})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_pred.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd5a31d-a368-47f2-b430-5916b1495180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa34703b-48e1-429b-a8b4-36fa92094306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   3.,   6.,   9.,  17.,  35.,  74., 105.,  79.,  31.]),\n",
       " array([0.13440678, 0.20003529, 0.2656638 , 0.3312923 , 0.3969208 ,\n",
       "        0.46254933, 0.5281778 , 0.59380633, 0.65943485, 0.72506332,\n",
       "        0.79069185]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(confidence_out[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3be74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_onehot = np.vstack([1-confidence_out.argmax(1), confidence_out.argmax(1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ebaf012-75af-46f4-af67-6713dacc7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = y_pred.argmax(1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e8007fd-b3f5-410f-a870-bf502d000565",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = confidence_out.argmax(1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c176f5b-d61a-4c5c-a37f-16559b7008d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 156, 0.0: 204})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_correct_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9e6c01-45ca-4ca0-8890-3cb835ab04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnn = pd.DataFrame({\"response\":response.astype(int).tolist(), \n",
    "              \"stim\":y_true[:, 1].astype(int).tolist(), \n",
    "             \"acc\":y_correct_pred[:, 1].astype(int).tolist(), \n",
    "             \"confidence\":rating.astype(int).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244fa8ef-c7fc-4a63-9d0c-b066ce646d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type2_proba(data):\n",
    "    data_result = {'proba_low_correct':[], \n",
    "                   'proba_high_correct':[], \n",
    "                  'proba_low_incorrect':[],\n",
    "                  'proba_high_incorrect':[], \n",
    "                  'proba_correct':[]}\n",
    "    \n",
    "    confidence_onehot = np.vstack([1-data[\"confidence\"], data[\"confidence\"]]).T\n",
    "    \n",
    "    idx_correct_trial = data[\"acc\"] == 1#正确的trial\n",
    "    idx_incorrect_trial = data[\"acc\"] == 0#错误的trial\n",
    "    \n",
    "    total_correct = sum(idx_correct_trial.astype(int))\n",
    "    total_incorrect = sum(idx_incorrect_trial.astype(int))\n",
    "    prob_correct = total_correct/len(data[\"acc\"])\n",
    "    correct_confidence =confidence_onehot[:, 1][idx_correct_trial]\n",
    "    \n",
    "    low_confidence = confidence_onehot[:, 0]\n",
    "    high_confidence = confidence_onehot[:, 1]\n",
    "    \n",
    "    low_correct =  sum(low_confidence[idx_correct_trial])/ total_correct\n",
    "    low_incorrect = sum(low_confidence[idx_incorrect_trial])/ total_incorrect\n",
    "    \n",
    "    high_correct = sum(high_confidence[idx_correct_trial])/ total_correct\n",
    "    high_incorrect = sum(high_confidence[idx_incorrect_trial])/ total_incorrect\n",
    "    \n",
    "    data_result['proba_low_correct'].append(low_correct)\n",
    "    data_result['proba_high_correct'].append(high_correct)\n",
    "    data_result['proba_low_incorrect'].append(low_incorrect)\n",
    "    data_result['proba_high_incorrect'].append(high_incorrect)\n",
    "    data_result['proba_correct'].append(prob_correct)\n",
    "    return  pd.DataFrame(data_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d692ce67-65ae-4b6c-9e1d-da7844fb502e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_low_correct</th>\n",
       "      <th>proba_high_correct</th>\n",
       "      <th>proba_low_incorrect</th>\n",
       "      <th>proba_high_incorrect</th>\n",
       "      <th>proba_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.25641</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.063725</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proba_low_correct  proba_high_correct  proba_low_incorrect  \\\n",
       "0            0.74359             0.25641             0.936275   \n",
       "\n",
       "   proba_high_incorrect  proba_correct  \n",
       "0              0.063725       0.433333  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_proba(df_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71fc15ee-120b-41d3-8377-3f075e1a933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub3 = pd.read_csv(\"../data/sub/sub3_metad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b99d062d-b985-410c-97fa-054b107c439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub3 = df_sub3.rename(columns = {\"rating\":\"confidence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02a383e3-cb38-471a-bbb1-e517b12ec470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_value(x):\n",
    "    if x[\"confidence\"] == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "220bcf01-18d6-4cec-a780-c6e0b1a7b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub3[\"confidence\"] = df_sub3.apply(lambda x: confidence_value(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217d9653-8d71-40cb-ae63-0961cfb3e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_low_correct</th>\n",
       "      <th>proba_high_correct</th>\n",
       "      <th>proba_low_incorrect</th>\n",
       "      <th>proba_high_incorrect</th>\n",
       "      <th>proba_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122881</td>\n",
       "      <td>0.877119</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.789298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proba_low_correct  proba_high_correct  proba_low_incorrect  \\\n",
       "0           0.122881            0.877119             0.619048   \n",
       "\n",
       "   proba_high_incorrect  proba_correct  \n",
       "0              0.380952       0.789298  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_proba(df_sub3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc2c671b-a95f-4e9f-94bf-0fda53dc067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cnn.to_csv(\"../data/sub/cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fdf9426-3424-4dda-9e93-d2d22527d96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stim  response  confidence\n",
       "0     0         0             143\n",
       "                1              73\n",
       "      1         0              24\n",
       "1     0         0              74\n",
       "                1               6\n",
       "      1         0              40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnn[\"count\"] = 1\n",
    "df_cnn.groupby([\"stim\", \"response\", \"confidence\"])[\"count\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b05fdd0-10f7-4066-ac7b-ade6161c03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stim  response  confidence\n",
       "0     0         0              29\n",
       "                1             135\n",
       "      1         0              15\n",
       "                1              12\n",
       "1     0         0              12\n",
       "                1               4\n",
       "      1         0              12\n",
       "                1              80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub3[\"count\"] = 1\n",
    "df_sub3.groupby([\"stim\", \"response\", \"confidence\"])[\"count\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41509f7f-9d81-4043-b1e2-a9d574d4e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fit_meta_d_MLE import fit_meta_d_MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec7c653c-4fd9-48ce-bc8e-21fb1b0ec7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/CNN_Moral-MetaCog/script/fit_meta_d_MLE.py:198: RuntimeWarning: divide by zero encountered in log\n",
      "  + nI_rS2[i]*np.log(prI_rS2[i]) for i in range(nRatings)])\n",
      "/root/miniconda3/envs/py38/lib/python3.8/site-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 99, function evaluations: 448, CG iterations: 172, optimality: 1.87e-06, constraint violation: 0.00e+00, execution time: 0.83 s.\n"
     ]
    }
   ],
   "source": [
    "CNN_nR_S1 = [73,143, 24, 0]\n",
    "CNN_nR_S2 = [13, 34, 28, 45]\n",
    "\n",
    "fit_cnn = fit_meta_d_MLE(CNN_nR_S1,CNN_nR_S2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c339ca3-451c-4140-95c6-92ed00ee2095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py38/lib/python3.8/site-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 102, function evaluations: 492, CG iterations: 175, optimality: 8.04e-07, constraint violation: 0.00e+00, execution time: 0.92 s.\n"
     ]
    }
   ],
   "source": [
    "sub2_nR_S1 = [135, 29, 15, 12]\n",
    "sub2_nR_S2 = [4, 12, 12, 80]\n",
    "\n",
    "fit_sub2 = fit_meta_d_MLE(sub2_nR_S1,sub2_nR_S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c8d77a3-bd6a-43df-8b50-9618936e00c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The drpime of CNN is  1.2763090464946976\n",
      "The meta drpime of CNN is  0.9103278817945828\n",
      "-----------------------------------------------\n",
      "The drpime of real subject 2 is  2.1186323152920803\n",
      "The meta drpime of real subject 2 is  2.481763276567043\n"
     ]
    }
   ],
   "source": [
    "print(\"The drpime of CNN is \", fit_cnn['da'])\n",
    "print(\"The meta drpime of CNN is \", fit_cnn['meta_da'])\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"The drpime of real subject 2 is \", fit_sub2['da'])\n",
    "print(\"The meta drpime of real subject 2 is \", fit_sub2['meta_da'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31ae37-b244-4621-b6f1-125b376b212a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce8bc0-3107-4649-93fc-f728a04d13e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
