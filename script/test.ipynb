{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe821d2f-7bfb-44ec-b53c-1bd5c3d2211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:03,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import commonsetting\n",
    "from models import perceptual_network, Encoder, Class_out, Conf_out\n",
    "from dataloader import CustomImageDataset, concatenate_transform_steps\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pretrained_model_name   = commonsetting.pretrained_model_name\n",
    "    hidden_layer_size       = commonsetting.hidden_layer_size\n",
    "    hidden_activation_name  = commonsetting.hidden_activation_name\n",
    "    hidden_activation       = commonsetting.hidden_activation\n",
    "    hidden_dropout          = commonsetting.hidden_dropout\n",
    "    resize                  = commonsetting.image_resize\n",
    "    in_shape                = (1,3,resize,resize)\n",
    "\n",
    "    SimpleCNN_args = dict(\n",
    "        pretrained_model_name   = pretrained_model_name,\n",
    "        hidden_layer_size       = hidden_layer_size,\n",
    "        hidden_activation       = hidden_activation,\n",
    "        hidden_dropout          = hidden_dropout,\n",
    "        hidden_layer_type       = commonsetting.hidden_layer_type,\n",
    "        output_layer_size       = commonsetting.output_layer_size,\n",
    "        in_shape                = (1,3,resize,resize),\n",
    "        retrain_encoder         = commonsetting.retrain_encoder,\n",
    "        device                  = commonsetting.device,\n",
    "        )\n",
    "        \n",
    "\n",
    "    tranformer_steps = concatenate_transform_steps(image_resize=commonsetting.image_resize, rotate=0)\n",
    "\n",
    "    dataset_test = CustomImageDataset(commonsetting.test_dir,label_map=commonsetting.label_map , transform=tranformer_steps)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=commonsetting.batch_size, shuffle=True, num_workers=commonsetting.num_workers)\n",
    "    SimpleCNN = perceptual_network(**SimpleCNN_args)\n",
    "    SimpleCNN.load_state_dict(torch.load(\"../models/train_mixed_weight/simplecnn_b32e4i224h300w2601.h5\"))\n",
    "    for p in SimpleCNN.parameters(): p.requires_grad = False\n",
    "    # define loss function\n",
    "    classification_loss = nn.BCELoss()\n",
    "    # when there is no noise\n",
    "    SimpleCNN.eval()\n",
    "    SimpleCNN.to(commonsetting.device)\n",
    "    with torch.no_grad():\n",
    "        # extract features of each image\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_correct_pred = []\n",
    "        confidence_out = []\n",
    "        for idx_batch, (batch_image, batch_label) in tqdm(enumerate(dataloader_test)):\n",
    "            batch_label = torch.vstack(batch_label).T.float()\n",
    "            #记得每一次处理数据之前要做这一步\n",
    "            batch_image = batch_image.to(commonsetting.device)\n",
    "            batch_label = batch_label.to(commonsetting.device)\n",
    "            \n",
    "            features,hidden_representation,prediction, confidence =  SimpleCNN(batch_image.to(commonsetting.device))\n",
    "            correct_preds = batch_label.clone().detach().argmax(1)==prediction.clone().detach().argmax(1)\n",
    "            correct_preds = correct_preds.float()\n",
    "\n",
    "            correct_preds = torch.vstack([1-correct_preds, correct_preds]).T.float()\n",
    "            \n",
    "            \n",
    "            y_correct_pred.append(correct_preds.detach().cpu().numpy())\n",
    "            y_true.append(batch_label.detach().cpu().numpy())\n",
    "            y_pred.append(prediction.detach().cpu().numpy())\n",
    "            confidence_out.append(confidence.detach().cpu().numpy())\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_correct_pred = np.concatenate(y_correct_pred, axis=0)\n",
    "    confidence_out = np.concatenate(confidence_out, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c9f356-4629-4a02-93c4-01168fe98bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ef5757-3322-42bc-be37-d12c46acd702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7867939814814816"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69652cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6496077935222673"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_correct_pred, confidence_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e639657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd104c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 104, 0: 170, 1: 86})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_pred.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd5a31d-a368-47f2-b430-5916b1495180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa34703b-48e1-429b-a8b4-36fa92094306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  3., 11., 12., 28., 66., 90., 77., 53., 16.]),\n",
       " array([0.16525538, 0.20818025, 0.25110513, 0.29402998, 0.33695486,\n",
       "        0.37987971, 0.42280459, 0.46572945, 0.5086543 , 0.55157918,\n",
       "        0.59450406]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(confidence_out[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3be74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_onehot = np.vstack([1-confidence_out.argmax(1), confidence_out.argmax(1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ebaf012-75af-46f4-af67-6713dacc7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = y_pred.argmax(1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e8007fd-b3f5-410f-a870-bf502d000565",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = confidence_out.argmax(1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c176f5b-d61a-4c5c-a37f-16559b7008d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 208, 0.0: 152})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_correct_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9e6c01-45ca-4ca0-8890-3cb835ab04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnn = pd.DataFrame({\"response\":response.astype(int).tolist(), \n",
    "              \"stim\":y_true[:, 1].astype(int).tolist(), \n",
    "             \"acc\":y_correct_pred[:, 1].astype(int).tolist(), \n",
    "             \"confidence\":rating.astype(int).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "244fa8ef-c7fc-4a63-9d0c-b066ce646d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type2_proba(data):\n",
    "    data_result = {'proba_low_correct':[], \n",
    "                   'proba_high_correct':[], \n",
    "                  'proba_low_incorrect':[],\n",
    "                  'proba_high_incorrect':[], \n",
    "                  'proba_correct':[]}\n",
    "    \n",
    "    confidence_onehot = np.vstack([1-data[\"confidence\"], data[\"confidence\"]]).T\n",
    "    \n",
    "    idx_correct_trial = data[\"acc\"] == 1#正确的trial\n",
    "    idx_incorrect_trial = data[\"acc\"] == 0#错误的trial\n",
    "    \n",
    "    total_correct = sum(idx_correct_trial.astype(int))\n",
    "    total_incorrect = sum(idx_incorrect_trial.astype(int))\n",
    "    prob_correct = total_correct/len(data[\"acc\"])\n",
    "    correct_confidence =confidence_onehot[:, 1][idx_correct_trial]\n",
    "    \n",
    "    low_confidence = confidence_onehot[:, 0]\n",
    "    high_confidence = confidence_onehot[:, 1]\n",
    "    \n",
    "    low_correct =  sum(low_confidence[idx_correct_trial])/ total_correct\n",
    "    low_incorrect = sum(low_confidence[idx_incorrect_trial])/ total_incorrect\n",
    "    \n",
    "    high_correct = sum(high_confidence[idx_correct_trial])/ total_correct\n",
    "    high_incorrect = sum(high_confidence[idx_incorrect_trial])/ total_incorrect\n",
    "    \n",
    "    data_result['proba_low_correct'].append(low_correct)\n",
    "    data_result['proba_high_correct'].append(high_correct)\n",
    "    data_result['proba_low_incorrect'].append(low_incorrect)\n",
    "    data_result['proba_high_incorrect'].append(high_incorrect)\n",
    "    data_result['proba_correct'].append(prob_correct)\n",
    "    return  pd.DataFrame(data_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d692ce67-65ae-4b6c-9e1d-da7844fb502e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_low_correct</th>\n",
       "      <th>proba_high_correct</th>\n",
       "      <th>proba_low_incorrect</th>\n",
       "      <th>proba_high_incorrect</th>\n",
       "      <th>proba_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proba_low_correct  proba_high_correct  proba_low_incorrect  \\\n",
       "0           0.153846            0.846154             0.342105   \n",
       "\n",
       "   proba_high_incorrect  proba_correct  \n",
       "0              0.657895       0.577778  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_proba(df_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71fc15ee-120b-41d3-8377-3f075e1a933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub3 = pd.read_csv(\"../data/sub/sub3_metad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b99d062d-b985-410c-97fa-054b107c439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub3 = df_sub3.rename(columns = {\"rating\":\"confidence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02a383e3-cb38-471a-bbb1-e517b12ec470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_value(x):\n",
    "    if x[\"confidence\"] == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "220bcf01-18d6-4cec-a780-c6e0b1a7b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub3[\"confidence\"] = df_sub3.apply(lambda x: confidence_value(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217d9653-8d71-40cb-ae63-0961cfb3e829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_low_correct</th>\n",
       "      <th>proba_high_correct</th>\n",
       "      <th>proba_low_incorrect</th>\n",
       "      <th>proba_high_incorrect</th>\n",
       "      <th>proba_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122881</td>\n",
       "      <td>0.877119</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.789298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proba_low_correct  proba_high_correct  proba_low_incorrect  \\\n",
       "0           0.122881            0.877119             0.619048   \n",
       "\n",
       "   proba_high_incorrect  proba_correct  \n",
       "0              0.380952       0.789298  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_proba(df_sub3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc2c671b-a95f-4e9f-94bf-0fda53dc067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cnn.to_csv(\"../data/sub/cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fdf9426-3424-4dda-9e93-d2d22527d96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stim  response  confidence\n",
       "0     0         0              43\n",
       "                1             167\n",
       "      1         0              14\n",
       "                1              16\n",
       "1     0         0              17\n",
       "                1              47\n",
       "      1         0              10\n",
       "                1              46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnn[\"count\"] = 1\n",
    "df_cnn.groupby([\"stim\", \"response\", \"confidence\"])[\"count\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b05fdd0-10f7-4066-ac7b-ade6161c03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stim  response  confidence\n",
       "0     0         0              29\n",
       "                1             135\n",
       "      1         0              15\n",
       "                1              12\n",
       "1     0         0              12\n",
       "                1               4\n",
       "      1         0              12\n",
       "                1              80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub3[\"count\"] = 1\n",
    "df_sub3.groupby([\"stim\", \"response\", \"confidence\"])[\"count\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41509f7f-9d81-4043-b1e2-a9d574d4e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fit_meta_d_MLE import fit_meta_d_MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec7c653c-4fd9-48ce-bc8e-21fb1b0ec7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py38/lib/python3.8/site-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n",
      "/root/autodl-tmp/CNN_Moral-MetaCog/script/fit_meta_d_MLE.py:198: RuntimeWarning: divide by zero encountered in log\n",
      "  + nI_rS2[i]*np.log(prI_rS2[i]) for i in range(nRatings)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 111, function evaluations: 556, CG iterations: 185, optimality: 3.74e-06, constraint violation: 0.00e+00, execution time:  1.1 s.\n"
     ]
    }
   ],
   "source": [
    "CNN_nR_S1 = [167,43, 14, 16]\n",
    "CNN_nR_S2 = [47, 17, 10, 46]\n",
    "\n",
    "fit_cnn = fit_meta_d_MLE(CNN_nR_S1,CNN_nR_S2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c339ca3-451c-4140-95c6-92ed00ee2095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py38/lib/python3.8/site-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 102, function evaluations: 492, CG iterations: 175, optimality: 8.04e-07, constraint violation: 0.00e+00, execution time: 0.94 s.\n"
     ]
    }
   ],
   "source": [
    "sub2_nR_S1 = [135, 29, 15, 12]\n",
    "sub2_nR_S2 = [4, 12, 12, 80]\n",
    "\n",
    "fit_sub2 = fit_meta_d_MLE(sub2_nR_S1,sub2_nR_S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c8d77a3-bd6a-43df-8b50-9618936e00c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The drpime of CNN is  1.0666976464688789\n",
      "The meta drpime of CNN is  0.5950653394482528\n",
      "-----------------------------------------------\n",
      "The drpime of real subject 2 is  2.1186323152920803\n",
      "The meta drpime of real subject 2 is  2.481763276567043\n"
     ]
    }
   ],
   "source": [
    "print(\"The drpime of CNN is \", fit_cnn['da'])\n",
    "print(\"The meta drpime of CNN is \", fit_cnn['meta_da'])\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"The drpime of real subject 2 is \", fit_sub2['da'])\n",
    "print(\"The meta drpime of real subject 2 is \", fit_sub2['meta_da'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31ae37-b244-4621-b6f1-125b376b212a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce8bc0-3107-4649-93fc-f728a04d13e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
