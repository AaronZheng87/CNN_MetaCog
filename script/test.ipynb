{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe821d2f-7bfb-44ec-b53c-1bd5c3d2211f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m dataloader_test \u001b[39m=\u001b[39m DataLoader(dataset_test, batch_size\u001b[39m=\u001b[39mcommonsetting\u001b[39m.\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39mcommonsetting\u001b[39m.\u001b[39mnum_workers)\n\u001b[1;32m     39\u001b[0m SimpleCNN \u001b[39m=\u001b[39m perceptual_network(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mSimpleCNN_args)\n\u001b[0;32m---> 40\u001b[0m SimpleCNN\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m../models/train_pixel_0.6/simplecnn_bs32e4i224h300.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m SimpleCNN\u001b[39m.\u001b[39mparameters(): p\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# define loss function\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/workspace/lib/python3.8/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    790\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/workspace/lib/python3.8/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1133\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/workspace/lib/python3.8/site-packages/torch/serialization.py:1101\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1100\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1101\u001b[0m     load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1103\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/workspace/lib/python3.8/site-packages/torch/serialization.py:1083\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1079\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39muntyped()\n\u001b[1;32m   1080\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1083\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1084\u001b[0m     dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/workspace/lib/python3.8/site-packages/torch/serialization.py:215\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 215\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    216\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/workspace/lib/python3.8/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    183\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/workspace/lib/python3.8/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "import commonsetting\n",
    "from models import perceptual_network, Encoder, Class_out, Conf_out\n",
    "from dataloader import CustomImageDataset, concatenate_transform_steps\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pretrained_model_name   = commonsetting.pretrained_model_name\n",
    "    hidden_layer_size       = commonsetting.hidden_layer_size\n",
    "    hidden_activation_name  = commonsetting.hidden_activation_name\n",
    "    hidden_activation       = commonsetting.hidden_activation\n",
    "    hidden_dropout          = commonsetting.hidden_dropout\n",
    "    resize                  = commonsetting.image_resize\n",
    "    in_shape                = (1,3,resize,resize)\n",
    "\n",
    "    SimpleCNN_args = dict(\n",
    "        pretrained_model_name   = pretrained_model_name,\n",
    "        hidden_layer_size       = hidden_layer_size,\n",
    "        hidden_activation       = hidden_activation,\n",
    "        hidden_dropout          = hidden_dropout,\n",
    "        hidden_layer_type       = commonsetting.hidden_layer_type,\n",
    "        output_layer_size       = commonsetting.output_layer_size,\n",
    "        in_shape                = (1,3,resize,resize),\n",
    "        retrain_encoder         = commonsetting.retrain_encoder,\n",
    "        device                  = commonsetting.device,\n",
    "        )\n",
    "        \n",
    "\n",
    "    tranformer_steps = concatenate_transform_steps(image_resize=commonsetting.image_resize, rotate=0)\n",
    "\n",
    "    dataset_test = CustomImageDataset(commonsetting.test_dir,label_map=commonsetting.label_map , transform=tranformer_steps)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=commonsetting.batch_size, shuffle=True, num_workers=commonsetting.num_workers)\n",
    "    SimpleCNN = perceptual_network(**SimpleCNN_args)\n",
    "    SimpleCNN.load_state_dict(torch.load(\"../models/train_pixel_0.6/simplecnn_bs32e4i224h300.h5\"))\n",
    "    for p in SimpleCNN.parameters(): p.requires_grad = False\n",
    "    # define loss function\n",
    "    classification_loss = nn.BCELoss()\n",
    "    # when there is no noise\n",
    "    SimpleCNN.eval()\n",
    "    SimpleCNN.to(commonsetting.device)\n",
    "    with torch.no_grad():\n",
    "        # extract features of each image\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_correct_pred = []\n",
    "        confidence_out = []\n",
    "        for idx_batch, (batch_image, batch_label) in tqdm(enumerate(dataloader_test)):\n",
    "            batch_label = torch.vstack(batch_label).T.float()\n",
    "            #记得每一次处理数据之前要做这一步\n",
    "            batch_image = batch_image.to(commonsetting.device)\n",
    "            batch_label = batch_label.to(commonsetting.device)\n",
    "            \n",
    "            features,hidden_representation,prediction, confidence =  SimpleCNN(batch_image.to(commonsetting.device))\n",
    "            correct_preds = batch_label.clone().detach().argmax(1)==prediction.clone().detach().argmax(1)\n",
    "            correct_preds = correct_preds.float()\n",
    "\n",
    "            correct_preds = torch.vstack([1-correct_preds, correct_preds]).T.float()\n",
    "            \n",
    "            \n",
    "            y_correct_pred.append(correct_preds.detach().cpu().numpy())\n",
    "            y_true.append(batch_label.detach().cpu().numpy())\n",
    "            y_pred.append(prediction.detach().cpu().numpy())\n",
    "            confidence_out.append(confidence.detach().cpu().numpy())\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_correct_pred = np.concatenate(y_correct_pred, axis=0)\n",
    "    confidence_out = np.concatenate(confidence_out, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c9f356-4629-4a02-93c4-01168fe98bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef5757-3322-42bc-be37-d12c46acd702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7939467592592594"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69652cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_correct_pred, confidence_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd104c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y_pred.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5a31d-a368-47f2-b430-5916b1495180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa34703b-48e1-429b-a8b4-36fa92094306",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(confidence_out[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_out.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_onehot = np.vstack([1-confidence_out.argmax(1), confidence_out.argmax(1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c176f5b-d61a-4c5c-a37f-16559b7008d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y_correct_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type2_correct(confidence, correct_trial):\n",
    "    confidence_onehot = np.vstack([1-confidence.argmax(1), confidence.argmax(1)]).T\n",
    "    idx_correct_trial = correct_trial == 1#正确的trial\n",
    "    total_correct = sum(idx_correct_trial.astype(int))\n",
    "    type2_acc =confidence_onehot[:, 1][idx_correct_trial]\n",
    "    return  sum(type2_acc), total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b14c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type2_correct, total_correct = type2_correct(confidence_out, y_correct_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57e4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "type2_correct/total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a25933-f837-41c4-95f9-c0e2b369521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type2_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f20fb-afb8-489a-9de7-1329f305206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798e27e-4a38-46c6-bff6-56766bc830b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c7dcd-8c9e-4ef8-91f7-c8678aa81328",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = y_pred.argmax(1) == 1\n",
    "response.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b42d01-8e61-471f-969a-bdec7a6dec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbfdf6-3189-4dfa-97bd-c71ddcf7b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = confidence_out.argmax(1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e6c01-45ca-4ca0-8890-3cb835ab04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnn = pd.DataFrame({\"response\":response.tolist(), \n",
    "              \"stim\":y_true[:, 1].astype(int).tolist(), \n",
    "             \"acc\":y_correct_pred[:, 1].astype(int).tolist(), \n",
    "             \"confidence\":rating.astype(int).tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c671b-a95f-4e9f-94bf-0fda53dc067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnn.to_csv(\"../result/reuslt_cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1430550c-d0ef-462d-b682-09d24689323b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
